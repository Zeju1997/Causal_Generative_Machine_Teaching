# -*- coding: utf-8 -*-
"""mnist-cgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V0pKshHYN2Vou5ZicEqXEqwbWDPuiGhc
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

import torch
import torch.nn as nn
from torchvision.datasets import ImageFolder, MNIST
from torchvision import transforms
from torch import autograd
from torch.autograd import Variable
from torchvision.utils import make_grid
from torch.utils.data import Dataset
from tqdm import tqdm

class BaseDataset(Dataset):
    def __init__(self, X, Y):
        self.data = X
        self.labels = Y

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
])

batch_size = 32

train_dataset = MNIST(root='data', train=True, download=True, transform=transform)
data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)

X = next(iter(data_loader))[0].numpy()
Y = next(iter(data_loader))[1].numpy()
(N, W, H) = train_dataset.data.shape
dim = W*H
X = X.reshape((N, dim))

class_1 = 3
class_2 = 5

# create new data set with class 1 as 0 and class 2 as 1
f = (Y == class_1) | (Y == class_2)
X = X[f]
Y = Y[f]
Y = np.where(Y == class_1, 0, 1)

nb_train = 10000
nb_test = 200

X_train = torch.tensor(X[:nb_train], dtype=torch.float)
y_train = torch.tensor(Y[:nb_train], dtype=torch.float)
X_test = torch.tensor(X[nb_train:nb_train + nb_test], dtype=torch.float)
y_test = torch.tensor(Y[nb_train:nb_train + nb_test], dtype=torch.float)

# proj_matrix = torch.empty(X.shape[1], self.opt.dim).normal_(mean=0, std=0.1)
# X_train = X_train @ proj_matrix
# X_test = X_test @ proj_matrix

data_train = BaseDataset(X_train, y_train)
data_test = BaseDataset(X_test, y_test)
train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size)
test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)


class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.label_embedding = nn.Embedding(2, 10)

        img_shape = (28, 28)

        self.model = nn.Sequential(
            nn.Linear(10 + int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 512),
            nn.Dropout(0.4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 512),
            nn.Dropout(0.4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 1),
        )

    def forward(self, img, labels):
        # Concatenate label embedding and image to produce input
        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)
        validity = self.model(d_in)
        return validity


class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.label_emb = nn.Embedding(2, 10)

        self.img_shape = (28, 28)

        self.hidden_dim = 100

        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat, 0.8))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *block(self.hidden_dim + 10, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(self.img_shape))),
            nn.Tanh()
        )

    def forward(self, noise, labels):
        # Concatenate label embedding and image to produce input
        gen_input = torch.cat((self.label_emb(labels), noise), -1)
        img = self.model(gen_input)
        img = img.view(img.size(0), *self.img_shape)
        return img


netG = Generator().cuda()
netD = Discriminator().cuda()

optimizer_D = torch.optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999), eps=1e-08, weight_decay=1e-04, amsgrad=False)
optimizer_G = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999), eps=1e-08, weight_decay=1e-04, amsgrad=False)

def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):
    g_optimizer.zero_grad()
    z = Variable(torch.randn(batch_size, 100)).cuda()
    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 1, batch_size))).cuda()
    fake_images = generator(z, fake_labels)
    validity = discriminator(fake_images, fake_labels)
    g_loss = criterion(validity, Variable(torch.ones(batch_size)).cuda())
    g_loss.backward()
    g_optimizer.step()
    return g_loss.item()

def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):
    d_optimizer.zero_grad()

    # train with real images
    real_validity = discriminator(real_images, labels)
    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).cuda())

    # train with fake images
    z = Variable(torch.randn(batch_size, 100)).cuda()
    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 1, batch_size))).cuda()
    fake_images = generator(z, fake_labels)
    fake_validity = discriminator(fake_images, fake_labels)
    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).cuda())

    d_loss = real_loss + fake_loss
    d_loss.backward()
    d_optimizer.step()
    return d_loss.item()

'''
num_epochs = 10
n_critic = 5
display_step = 50
for epoch in tqdm(range(num_epochs)):
    print('Starting epoch {}...'.format(epoch), end=' ')
    for i, (images, labels) in enumerate(train_loader):
        
        step = epoch * len(data_loader) + i + 1
        real_images = Variable(images).cuda()
        labels = Variable(labels).cuda()
        netG.train()
        
        d_loss = 0
        for _ in range(n_critic):
            d_loss = discriminator_train_step(len(real_images), netD,
                                              netG, optimizer_D, criterion,
                                              real_images, labels)
        

        g_loss = generator_train_step(batch_size, netD, netG, optimizer_G, criterion)
        
        
        #if step % display_step == 0:
        #    generator.eval()
        #    z = Variable(torch.randn(9, 100)).cuda()
         #   labels = Variable(torch.LongTensor(np.arange(9))).cuda()
        #    sample_images = generator(z, labels).unsqueeze(1)
         #   grid = make_grid(sample_images, nrow=3, normalize=True)
    print('Done!')
'''

# Commented out IPython magic to ensure Python compatibility.
n_epochs = 5
n_critic = 5
display_step = 50

adversarial_loss = torch.nn.BCELoss()

# Create the generator
# netG = Generator(self.opt).cuda()
# netD = cgan.Discriminator(self.opt).cuda()

# optimizer_D = optim.Adam(discriminator.parameters(), lr=self.opt.lr, betas=(self.opt.b1, self.opt.b2))
# optimizer_G = optim.Adam(generator.parameters(), lr=self.opt.lr, betas=(self.opt.b1, self.opt.b2))
step = 0

for epoch in tqdm(range(n_epochs)):
    for i, (imgs, labels) in enumerate(train_loader):

      batch_size = imgs.shape[0]

      # Adversarial ground truths
      valid = Variable(torch.cuda.FloatTensor(batch_size, ).fill_(1.0), requires_grad=False)
      fake = Variable(torch.cuda.FloatTensor(batch_size, ).fill_(0.0), requires_grad=False)

      # Configure input
      real_imgs = Variable(imgs.type(torch.cuda.FloatTensor))
      labels = Variable(labels.type(torch.cuda.LongTensor))

      # -----------------
      #  Train Generator
      # -----------------

      optimizer_G.zero_grad()

      # Sample noise and labels as generator input
      dim = 100
      z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, dim))))

      # self.opt.n_classes = 2
      indices = np.random.randint(2, size=batch_size).astype(int)
      # classes = np.array([class_1, class_2])
      classes = np.array([0, 1])
      labels = classes[indices]
      gen_labels = Variable(torch.cuda.LongTensor(labels))
      labels = Variable(torch.cuda.LongTensor(labels))
      # gen_labels = Variable(torch.cuda.LongTensor(np.random.randint(0, self.opt.n_classes, batch_size)))

      # z = torch.cat((z, gen_labels.unsqueeze(0)), dim=1)
      # Generate a batch of images
      gen_imgs = netG(z, gen_labels)

      # Loss measures generator's ability to fool the discriminator
      validity = netD(gen_imgs, gen_labels)
      g_loss = adversarial_loss(validity, valid.unsqueeze(1))

      g_loss.backward()
      optimizer_G.step()

      # ---------------------
      #  Train Discriminator
      # ---------------------

      optimizer_D.zero_grad()

      # Loss for real images
      validity_real = netD(real_imgs, labels)
      d_real_loss = adversarial_loss(validity_real, valid)

      # Loss for fake images
      validity_fake = netD(gen_imgs.detach(), gen_labels)
      d_fake_loss = adversarial_loss(validity_fake, fake)

      # Total discriminator loss
      d_loss = (d_real_loss + d_fake_loss) / 2

      d_loss.backward()
      optimizer_D.step()

      step = step + 1

      '''
      print(
          "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"
#            % (epoch, n_epochs, i, len(train_loader), d_loss.item(), g_loss.item())
      )
      '''

z = Variable(torch.randn(100, 100)).cuda()
labels1 = torch.LongTensor([i for i in range(2) for _ in range(2)]).cuda()

labels_3 = torch.zeros(50).cuda()
labels_5 = torch.ones(50).cuda()
labels = torch.cat((labels_3, labels_5), dim=0)

indices = torch.randint(2, (100, ))
classes = torch.tensor([0, 1])
labels = classes[indices].cuda()

images = netG(z, labels).unsqueeze(1).cpu()

grid = make_grid(images, nrow=10, normalize=True)

fig, ax = plt.subplots(figsize=(10, 10))
ax.imshow(grid.permute(1, 2, 0).data, cmap='binary')
ax.axis('off')


def generate_digit(generator, digit):
    z = Variable(torch.randn(1, 100)).cuda()
    label = torch.LongTensor([digit]).cuda()
    img = generator(z, label).data.cpu()
    img = 0.5 * img + 0.5
    return transforms.ToPILImage()(img)

generate_digit(netG, 1)
